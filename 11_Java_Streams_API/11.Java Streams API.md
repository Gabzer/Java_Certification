# Part 1

## Characteristics of Streams

Stream is an immutable flow of elements which can be processed _sequentially_, which is the default, or _parallelly_.
You could vaguely compare the way the streams process content to a loop. But that's not entirely correct. The loop is always processing things sequentially.

```java
List<Product> list = new ArraysList();
```

```java
for (Product p: list) {     //  LOOP
    if (p.getPrice()>10) {
        p.setDiscount(0.2);
    }
}
```

```java
list.stream().parallel()    //  STREAM
             .filter(p->p.getPrice()>10)
             .forEach(p->p.setDiscount(0.2));
```

## Create Streams Using Stream API

```java
/*
*BaseStream
*   Stream
*   DoubleStream
*   IntStream
*   LongStream
*/
```

The reason we have Double, Int, and LongStreams is purely to avoid extra boxing, unboxing of primitives when we convert a primitive to the object and object to the primitive.
All streams can use generics.
Stream can be obtained from any collection or array by using static methods of a stream class (ex.: Stream.of()).

```java
IntStream.generate(() -> (int)(Math.random()*10)).takeWhile(n->n!=3).sum();     //  generating an infinite flow of numbers
Stream.of(new Food(), new Drink).forEach(p->p.setPrice(1));
```

## Stream Pipeline Processing Operations

**Intermediate** - perform action and produce another stream. (filter, map, flatMap, peek, distinct, sorted, dropWhile, skip, (short-circuit:) limit, takeWhile).
**Terminal** - traverse stream pipeline and _end_ the strem processing. (forEach, forEachOrdered, count, min, max, sum, average, collect, reduce, (short-circuit:) allMatch, anyMatch, noneMatch, findAny, findFirst).
**Short-circuit** - produce finite result, even if presented qith infinite input.
Basic function purposes:
1.Predicate - performs tests;
2.Function - converts types;
3.UnaryOperator - (variant of function) converts values;
4.Consumer - processes elements;
5.Supplier - produces elements.

## Using Functional Interfaces

java.util.function

```java
List<Product> list = new ArraysList();
list.stream()
    .filter(p->p.setDiscount() == 0)    //  Predicate
    .peek(p->p.applyDiscount(0.1))      //  Consumer
    .map(p->p.getBestBefore())          //  Function
    .forEach(d->d.plusDays(1));         //  Consumer
```




# Part 2

## Bi-argument Variants of Functional Interfaces

Why would you need these Bi-argument variants?

```java
Map<Product, Integer> items = new HashMap();
list.forEach((p, q) -> p.getPrice().multiply(BigDecimal.valueOf(q.intValue())));
```

I don't want to process just Products or just Integers, presumably quantity of that Product, or just these quantities, I want to process them both at the same time.

## Perform Actions with Stream Pipeline Elements

**Consumer<T>**
Operations **peek**, **forEach** and **forEachOrdered** accept _Consumer<T>_ interface.

```java
Consumer<Product> expireProduct = (p) -> p.setBestBefore(LocalDate.now());
Consumer<Product> discountProduct = (p) -> p.setDiscount(BigDecimal.valueOf(0.1));

list.stream().forEach(expireProduct.andThen(discountProduct));
```

method **.andThen()** - I've got this action and that action, and I want to fuse these actions together.

Alternatively, you could apply this action separately. Maybe you want to apply the action which sets the best before date first. But then you want to do some filtering, and only to those objects that are left in the stream after you apply the filtering, only to those you want to apply that discount.

```java
list.stream().peek(expireProduct)
             .filter(p.getPrice().compareTo(BigDecimal.valueOf(10)) > 0)
             .forEach(discountProduct);
```

## Perform Filtering with Stream Pipeline Elements

**Predicate<T>**
method **.filter()** accepts _Predicate<T>_ interface and returns a stream comprising only elements that satisfy the filter criteria.
Default methods provided by the _Predicate_:
1.**.and()** combines predicate like the && operator;
2.**.or()** combines predicate like the || operator;
3.**.negate()** returns a predicate that represents the logical negation of predicate.
Static methods provided by the _Predicate_ interface:
1.**.not()** returns a predicate that is the negation of the supplied predicate;
2.**.isEqual()** returns a predicate that compares the supplied object with the contents of the collection.

```java
Predicate<Product> foodFilter = p -> p instanceof Food;
Predicate<Product> priceFilter = p -> p.getPrice().compareTo(BigDecimal.valueOf(2)) < 0;

list.stream().filter(foodFilter.negate().or(priceFilter))
             .forEach(p -> p.setDiscount(BigDecimal.valueOf(0.1)));
list.stream().filter(Predicate.isEqual(new Food("Cake"), BigDecimal.valueOf(1.99)))
             .forEach(p -> p.setDiscount(BigDecimal.valueOf(0.1)));
```

## Perform Mapping of Stream Pipeline Elements

**Function<T, R>**
Difference between **Function** and _UnaryOperator_ ? Function: T is the source and R destination type; UNaryOperator: describes a single type.
method **.map()** accepts a _Funtion<T,R>_ interface and returns a new stream comprising elements produced by this function based on the original stream content.
Default methods provided by the _Function_:
1.**.andThen()** and **.compose()** combine function together (one is the opposite of the other).
Static methods provided by the _Function_ interface:
1.**.identity()** returns a function that aways return its input argument (equivalent of t->t fucntion).

```java
Function<Product, String> nameMapper = p -> p.getName();
UnaryOperator<String> trimMapper = n -> n.trim();
ToIntFunction<String> lengthMapper = n -> n.length();

list.stream().map(nameMapper.andThen(trimMapper)).mapToInt(lengthMapper).sum(); //  the result of this stream processing will be 
                                                                                //  the total sum of all product name lengths
```

## Join Streams using flatMap Operation

What a method **flatMap** will do, it will allow me to combine these different streams into a single stream. It allows me to ignore the origin from which order these or the other item came, and just join them to one stream.
Flatten a number of streams into a single stream.

## Other Intermediate Stream Operations

**distinct()** returns a stream with no duplicates;
**sorted()** and **sorted(Comparator<T> t)** rearrange the order of elements;
**skip(long l)** skips a number of elements in the stream;
**takeWhile(Predicate p)** takes elements from the stream whole they match the predicate;
**dropWhile(Predicate p)** removes elements from the stream while they match the predicate;
**limit(long l)** retruns a stream of elements limited to given size.

```java
Stream.of("A","C","B","D","B","D")
      .distinct()                       //  A,C,B,D
      .sorted()                         //  A,B,C,D
      .skip(2)                          //  C,D
      .forEach(s -> s.toLowerCase());   //  c,d
```

```java
Stream.of("B","C","A","E","D","F")
      .takeWhile(s->!s.equals("D"))     //  B,C,A,E
      .dropWhile(s->!s.equals("C"))     //  C,A,E
      .limit(2)                         //  C,A
      .forEach(s -> s.toLowerCase());   //  c,a
```

## Short-Circuit Terminal Operations

**allMatch(Predicate p)** returns true if all elements in the stream match the predicate;
**allMatch(Predicate p)** returns true if any elements in the stream match the predicate;
**allMatch(Predicate p)** returns true if no elements in the stream match the predicate;
**findAny()** returns an element from the stream wrapped in Optional object;
**findFirst()** returns the first element from the stream wrapped in Optional object.

```java
String[] vallues = {"RED", "GREEN", "BLUE"};
boolean allGreen = Arrays.stream(values).allMatch(s->s.equals("GREEN"));    //  false
boolean anyGreen = Arrays.stream(values).anyMatch(s->s.equals("GREEN"));    //  true
boolean noneGreen = Arrays.stream(values).noneMatch(s->s.equals("GREEN"));  //  false
Optional<String> anyColour = Arrays.stream(values).findAny();                //  retuns any element
Optional<String> firstColour = Arrays.stream(values).findFirst();            //  "RED"
```

**Optional object** - you don't have to, necessarily, produce an exception if a stream is empty.

## Process Stream Using count, min, max, sum, average Operations

Terminal operations calculate values from stream content.

## Aggregate Stream Data Using reduce Operation

If count, min, max, average are specialized methods that have a particular algorithm, then reduce is a generic way of doing the string reduction. By reduction, we mean, getting all data from a stream and producing some value.
Why would you want to use a reduce? Because you want to have a reduction that's neither one of the simple ones, like count, min, max, sum, whatever.

**Optional<T> reduce(BinaryOperator<T> accumulator)** performs accumulation of elements;
**T reduce(T identity, BinaryOperator<T> accumulator)** identity acts as initial (default) value;
**<U> U reduce(U identity, BiFunction<U,T,U> accumulator, BinaryOperator<U> combiner)** BiFunction performs both value mapping and accumulation of value. BinaryOperator combines results produced by the BiFunction in parallel stream handling mode.

```java
Optional<String> x1 = list.stream()
                          .map(p->p.getName())
                          .reduce((s1,s2)->s1+" "+s2);
String x2 = list.stream()
                .map(p->p.getName())
                .reduce("", (s1,s2)->s1+" "+s2);
String x3 = list.stream()
                .parallel()
                .reduce("", (s,p)->p.getName()+" "+s, (s1,s2)->s1+s2);
```

The last example here is sort of designed to do it in a parallelized mode by splitting the stream into subsets, accumulating intermediate results per subset, and then combining these intermediate results together into one final result.

## General Logic of the collect Operation

**Collector** - could combine several actions in one go.
It's exactly what the reduction function was doing in the previous page _plus_ it also contains a supplier of values. So you can generate stuff. You can accumulate it. And you can combine their accumulated results.
There are also a number of pre-written Collectors you could use. So in a collect method, you can just specify which Collector you would like to use. And then you can also apply post-processing to the collector. It's called a **finisher**.

Produces new result containers using **Supplier**;
Accumulates data elements into these result containers using **BiConsumer**;
Combines result containers using **BinaryOperator**;
Optionally performs a final transform of the processing result using the **Function**.

```java
stream.collect(<supplier>, <accumulator>, <combiner>);
stream.collect(<collector>);
stream.collect(Collectors.collectingAndThen(<collector>, <finisher>));
```

## Using Basic Collectors

**Claculating summary values** such as average, min, max, count, sum:

```java
DoubleSummaryStatistics stats =
    list.stream()
        .collect(Collectors.summarizingDouble(p->p.getPrice().doubleValue()));
```

**Mapping** and **joining** stream elements:

```java
String s1 =
    list.stream()
        .collect(Collectors.mapping(p->p.getName(), Collectors.joining(",")));  //  concat all strings and add , beteewn then
```

**Gathering** stream elements into a collection such as list, set, or map:

```java
List<Product> drinks =
    list.stream()
        .filter(p->p instanceof Drink).collect(Collectors.toList());
```

## Perform a Conversion of a Collector Result

Add finisher function to a collector to perform conversion of the collect result.

```java
NumberFormat fmt = NumberFormat.getCurrencyInstance(Locale.UK);
String s2 = list.stream()
                .collect(Collectors.collectingAndThen(
                    Collectors.averagingDouble(
                        p->p.getPrice().doubleValue()),
                        n->fmt.format(n)));
```

Method **Collectors.collectingAndThen** appends a finishing _Function_ to a _Collector_.

## Perform Grouping or Partitioning of the Stream Content

The contents of the stream can be grouped and partitioned.
**partitioningBy** which basically takes the entire stream content and applies some kind of Boolean expression here, which is a _predicate_, as you can guess, which splits the stream into two groups, a group for which this expression returned true, and a group for which this expression returned false. And the result is a map object which uses Boolean as the map key. So there are only two entries in that map, true and false entry. And then each entry will contain the list of whatever we want to put inside that map, in this particular case, a list of products, for example.
**groupingBy** allows you to use a function to derive the grouping key. And again, you end up with a map. So in this particular case, I'm grouping all products by their best before date. So for each best before date, I'll have an entry in the map, and then a list of products associated with that particular best before date that's grouping for you.

## Mapping and Filtering with Respect to Groups or Particions

**flatMapping** collector is applied to each input element in the stream before accumulation;
**filtering** collector eliminates content from the stream whitout removing an entire group, if the group tuirns out to be empty.

**example**: class Order has Customer customer; LocalDate date; List<Product> items;
-Joe, 2018-11-21, [{Tea, 1.99}, {Cake, 2.99}]
-Bob, 2018-11-21, [{Coffee, 1.99}]
-Joe, 2018-11-22, [{Coffee, 1.99}, {Cake, 2.99}]

```java
Map<Customer, Set<Product>> customerProducts =
    orders.collect(Collectors.groupingBy(o->o.getCustomer(),
                  .Collectors.flatMapping(o->o.getItems().stream(),
                                            Collectors.toSet())));
//  {Joe=[Tea, Coffee, Cake], Bob=[Coffee]}
```

```java
Map<Customer, Set<Order>> customerOrdersOnDate =
    orders.collect(Collectors.groupingBy(o->o.getCustomer(),
                  .Collectors.filtering(o->o.getDate().equals(LocalDate.of(2018,11,22)),
                                            Collectors.toSet())));
//  {Joe=[Order[date=2018-11-22, customer Joe, products=[Coffee, Cake]]], Bob=[]}
```

## Parallel Stream Processing

By default, processing is sequential.
**.stream().parallel()** or **.stream().sequential()**
_Now how the parallel actually physically functions?_ So the entire inbound content that a stream produces will be split into subsets. And these subsets could be split into further subsets. And these could be split into further subsets. And then the processing will be applied to each subset, and then the results will be combined.
The **purpose** of this subset division is to be able to process subsets on different CPU cores in parallel.
There is no way on earth you can predict which subset will be processed earlier or later than the other subset. Nobody can predict that.

## Parallel Stream Processing Guidelines

Guidelines that helps you understand what cases are suitable and what cases are not suitable for parallel processing. So there are three criteria you need to consider:
**Stateless** - state of one element must not affect a state of another;
**Non-interfering** - you mustn't modify the source of information;
**Associative** - results must not be affected by the order of operants.

## Restrictions on Parallel Stream Processing

You can't do it: (corrupt memory and slow down processing)
1.you shouldn't do is perform operations that require sequential access to a shared resource;
2.do not perform operations that modify shared resource.

You can do it:
1.Stream contains large number of elements;
2.multiple CPU core are available to physically parallelize computaions;
3.processing of stream elements requires significant CPU resources.



# Quiz

Which statement is NOT true about Java Streams?
Stream pipeline traversal uses method chaining.
Pipeline traversal occurs starting with the first stream method encountered. <----- OK
After an element is processed, it is no longer available from the stream.
Stream processing can be sequential.

What would you use while processing a stream to replace every element in a stream with a different value?
Function <----- OK

Which statement is true about intermediate stream operations?
They perform an action and produce another stream. <----- OK

What kind of interface does the filter method in a stream accept?
Predicate <----- OK